---
title: On the Sample Complexity of Stability Constrained Imitation Learning
abstract: 'We study the following question in the context of imitation learning for
  continuous control: how are the underlying stability properties of an expert policy
  reflected in the sample complexity of an imitation learning task?  We provide the
  first results showing that a granular connection can be made between the expert
  systemâ€™s incremental gain stability, a novel measure of robust convergence between
  pairs of system trajectories, and the dependency on the task horizon T of the resulting
  generalization bounds. As a special case, we delineate a class of systems for which
  the number of trajectories needed to achieve epsilon-suboptimality is sublinear
  in the task horizon T, and do so without requiring (strong) convexity of the loss
  function in the policy parameters.  Finally, we conduct numerical experiments demonstrating
  the validity of our insights on both a simple nonlinear system with tunable stability
  properties, and on a high-dimensional quadrupedal robotic simulation.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tu22a
month: 0
tex_title: On the Sample Complexity of Stability Constrained Imitation Learning
firstpage: 180
lastpage: 191
page: 180-191
order: 180
cycles: false
bibtex_author: Tu, Stephen and Robey, Alexander and Zhang, Tingnan and Matni, Nikolai
author:
- given: Stephen
  family: Tu
- given: Alexander
  family: Robey
- given: Tingnan
  family: Zhang
- given: Nikolai
  family: Matni
date: 2022-05-11
address:
container-title: Proceedings of The 4th Annual Learning for Dynamics and Control Conference
volume: '168'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 11
pdf: https://proceedings.mlr.press/v168/tu22a/tu22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
