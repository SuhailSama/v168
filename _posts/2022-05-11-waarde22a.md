---
title: Training Lipschitz Continuous Operators Using Reproducing Kernels
abstract: This paper proposes that Lipschitz continuity is a natural outcome of regularized
  least squares in kernel-based learning. Lipschitz continuity is an important proxy
  for robustness of input-output operators. It is also instrumental for guaranteeing
  closed-loop stability of kernel-based controlllers through small incremental gain
  arguments. We introduce a new class of nonexpansive kernels that are shown to induce
  Hilbert spaces consisting of only Lipschitz continuous operators. The Lipschitz
  constant of estimated operators within such Hilbert spaces can be tuned by suitable
  selection of a regularization parameter. As is typical for kernel-based models,
  input-output operators are estimated from data by solving tractable systems of linear
  equations. The approach thus constitutes a promising alternative to Lipschitz-bounded
  neural networks, that have recently been investigated but are computationally expensive
  to train.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: waarde22a
month: 0
tex_title: Training Lipschitz Continuous Operators Using Reproducing Kernels
firstpage: 221
lastpage: 233
page: 221-233
order: 221
cycles: false
bibtex_author: Waarde, Henk van and Sepulchre, Rodolphe
author:
- given: Henk van
  family: Waarde
- given: Rodolphe
  family: Sepulchre
date: 2022-05-11
address:
container-title: Proceedings of The 4th Annual Learning for Dynamics and Control Conference
volume: '168'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 11
pdf: https://proceedings.mlr.press/v168/waarde22a/waarde22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
