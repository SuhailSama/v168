---
title: Experience Replay with Likelihood-free Importance Weights
abstract: The use of past experiences to accelerate temporal difference (TD) learning
  of value functions, or experience replay, is a key component in deep reinforcement
  learning methods such as actor-critic.In this work, we propose to re-weight experiences
  based on their likelihood under the stationary distribution of the current policy,
  and justify this with a contraction argument over the Bellman evaluation operator.
  The resulting TD objective encourages small approximation errors on the value function
  over frequently encountered states.  To balance bias (from off-policy experiences)
  and variance (from on-policy experiences), we use a likelihood-free density ratio
  estimator between on-policy and off-policy experiences, and use the learned ratios
  as the prioritization weights. We apply the proposed approach empirically on Soft
  Actor Critic (SAC), Double DQN and Data-regularized Q(DrQ), over 12 Atari environments
  and 6 tasks from the DeepMind control suite. We achieve superior sample complexity
  on 9 out of 12 Atari environments and 16 out of 24 method-task combinations for
  DCS compared to the best baselines.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sinha22a
month: 0
tex_title: Experience Replay with Likelihood-free Importance Weights
firstpage: 110
lastpage: 123
page: 110-123
order: 110
cycles: false
bibtex_author: Sinha, Samarth and Song, Jiaming and Garg, Animesh and Ermon, Stefano
author:
- given: Samarth
  family: Sinha
- given: Jiaming
  family: Song
- given: Animesh
  family: Garg
- given: Stefano
  family: Ermon
date: 2022-05-11
address:
container-title: Proceedings of The 4th Annual Learning for Dynamics and Control Conference
volume: '168'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 11
pdf: https://proceedings.mlr.press/v168/sinha22a/sinha22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
