---
title: 'Control-Tutored Reinforcement Learning: Towards the Integration of Data-Driven
  and Model-Based Control'
abstract: We present an architecture where a feedback controller derived on an approximate
  model of the environment assists the learning process to enhance its data efficiency.
  This architecture, which we term as Control-Tutored Q-learning (CTQL), is presented
  in two alternative flavours. The former is based on defining the reward function
  so that a Boolean condition can be used to determine when the control tutor policy
  is adopted, while the latter, termed as probabilistic CTQL (pCTQL), is instead based
  on executing calls to the tutor with a certain probability during learning. Both
  approaches are validated, and thoroughly benchmarked against Q-Learning, by considering
  the stabilization of an inverted pendulum as defined in OpenAI Gym as a representative
  problem.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lellis22a
month: 0
tex_title: 'Control-Tutored Reinforcement Learning: Towards the Integration of Data-Driven
  and Model-Based Control'
firstpage: 1048
lastpage: 1059
page: 1048-1059
order: 1048
cycles: false
bibtex_author: Lellis, Francesco De and Coraggio, Marco and Russo, Giovanni and Musolesi,
  Mirco and di Bernardo, Mario
author:
- given: Francesco De
  family: Lellis
- given: Marco
  family: Coraggio
- given: Giovanni
  family: Russo
- given: Mirco
  family: Musolesi
- given: Mario
  family: Bernardo
  prefix: di
date: 2022-05-11
address:
container-title: Proceedings of The 4th Annual Learning for Dynamics and Control Conference
volume: '168'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 11
pdf: https://proceedings.mlr.press/v168/lellis22a/lellis22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
