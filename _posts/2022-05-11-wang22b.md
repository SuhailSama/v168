---
title: Learning Linear Models Using Distributed Iterative Hessian Sketching
abstract: This work considers the problem of learning the Markov parameters of a linear
  system from observed data. Recent  non-asymptotic system identification results
  have characterized the sample complexity of this problem in the single and multi-rollout
  setting. In both instances, the number of samples required in order to obtain acceptable
  estimates can produce optimization problems with an intractably large number of
  decision variables for a second-order algorithm. We show that a randomized and distributed
  Newton algorithm based on Hessian-sketching can produce  $\epsilon$-optimal solutions
  and converges geometrically. Moreover, the algorithm is trivially parallelizable.
  Our results hold for a variety of sketching matrices and we illustrate the theory
  with numerical examples.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang22b
month: 0
tex_title: Learning Linear Models Using Distributed Iterative Hessian Sketching
firstpage: 427
lastpage: 440
page: 427-440
order: 427
cycles: false
bibtex_author: Wang, Han and Anderson, James
author:
- given: Han
  family: Wang
- given: James
  family: Anderson
date: 2022-05-11
address:
container-title: Proceedings of The 4th Annual Learning for Dynamics and Control Conference
volume: '168'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 11
pdf: https://proceedings.mlr.press/v168/wang22b/wang22b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
