---
title: Adaptive Variants of Optimal Feedback Policies
abstract: The stable combination of optimal feedback policies with online learning
  is studied in a new control-theoretic framework for uncertain nonlinear systems.
  The framework can be systematically used in transfer learning and sim-to-real applications,
  where an optimal policy learned for a nominal system needs to remain effective in
  the presence of significant variations in parameters. Given unknown parameters within
  a bounded range, the resulting adaptive control laws guarantee convergence of the
  closed-loop system to the state of zero cost. Online adjustment of the learning
  rate is used as a key stability mechanism, and preserves certainty equivalence when
  designing optimal policies. The approach is illustrated on the familiar mountain
  car problem, where it yields near-optimal performance despite the presence of parametric
  model uncertainty.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lopez22a
month: 0
tex_title: Adaptive Variants of Optimal Feedback Policies
firstpage: 1125
lastpage: 1136
page: 1125-1136
order: 1125
cycles: false
bibtex_author: Lopez, Brett and Slotine, Jean-Jacques
author:
- given: Brett
  family: Lopez
- given: Jean-Jacques
  family: Slotine
date: 2022-05-11
address:
container-title: Proceedings of The 4th Annual Learning for Dynamics and Control Conference
volume: '168'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 11
pdf: https://proceedings.mlr.press/v168/lopez22a/lopez22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
