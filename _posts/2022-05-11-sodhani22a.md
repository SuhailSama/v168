---
title: Block Contextual MDPs for Continual Learning
abstract: In reinforcement learning (RL), when defining a Markov Decision Process
  (MDP), the environment dynamics are implicitly assumed to be stationary. This assumption
  of stationarity, while simplifying, can be unrealistic in many scenarios. In the
  continual reinforcement learning scenario, the sequence of tasks is another source
  of nonstationarity. In this work, we propose to examine this continual reinforcement
  learning setting through the Block Contextual MDP (BC-MDP) framework, which enables
  us to relax the assumption of stationarity. This framework challenges RL algorithms
  to handle both nonstationarity and rich observation settings and, by additionally
  leveraging smoothness properties, enables us to study generalization bounds for
  this setting. Finally, we take inspiration from adaptive control to propose a novel
  algorithm that addresses the challenges introduced by this more realistic BC-MDP
  setting, allows for zero-shot adaptation at evaluation time, and achieves strong
  performance on several nonstationary environments.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sodhani22a
month: 0
tex_title: Block Contextual MDPs for Continual Learning
firstpage: 608
lastpage: 623
page: 608-623
order: 608
cycles: false
bibtex_author: Sodhani, Shagun and Meier, Franziska and Pineau, Joelle and Zhang,
  Amy
author:
- given: Shagun
  family: Sodhani
- given: Franziska
  family: Meier
- given: Joelle
  family: Pineau
- given: Amy
  family: Zhang
date: 2022-05-11
address:
container-title: Proceedings of The 4th Annual Learning for Dynamics and Control Conference
volume: '168'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 11
pdf: https://proceedings.mlr.press/v168/sodhani22a/sodhani22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
