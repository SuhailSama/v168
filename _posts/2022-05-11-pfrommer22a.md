---
title: Safe Reinforcement Learning with Chance-constrained Model Predictive Control
abstract: Real-world reinforcement learning (RL) problems often demand that agents
  behave safely by obeying a set of designed constraints. We address the challenge
  of safe RL by coupling a safety guide based on model predictive control (MPC) with
  a modified policy gradient framework in a linear setting with continuous actions.
  The guide enforces safe operation of the system by embedding safety requirements
  as chance constraints in the MPC formulation. The policy gradient training step
  then includes a safety penalty which trains the base policy to behave safely. We
  show theoretically that this penalty allows for a provably safe optimal base policy
  and illustrate our method with a simulated linearized quadrotor experiment.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: pfrommer22a
month: 0
tex_title: Safe Reinforcement Learning with Chance-constrained Model Predictive Control
firstpage: 291
lastpage: 303
page: 291-303
order: 291
cycles: false
bibtex_author: Pfrommer, Samuel and Gautam, Tanmay and Zhou, Alec and Sojoudi, Somayeh
author:
- given: Samuel
  family: Pfrommer
- given: Tanmay
  family: Gautam
- given: Alec
  family: Zhou
- given: Somayeh
  family: Sojoudi
date: 2022-05-11
address:
container-title: Proceedings of The 4th Annual Learning for Dynamics and Control Conference
volume: '168'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 11
pdf: https://proceedings.mlr.press/v168/pfrommer22a/pfrommer22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
