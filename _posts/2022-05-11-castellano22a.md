---
title: Reinforcement Learning with Almost Sure Constraints
abstract: In this work we address the problem of finding feasible policies for Constrained
  Markov Decision Processes under probability one constraints. We argue that stationary
  policies are not sufficient for solving this problem, and that a rich class of policies
  can be found by endowing the controller with a scalar quantity, so called budget,
  that tracks how close the agent is to violating the constraint. We show that the
  minimal budget required to act safely can be obtained as the smallest fixed point
  of a Bellman-like operator, for which we analyze its convergence properties. We
  also show how to learn this quantity when the true kernel of the Markov decision
  process is not known, while providing sample-complexity bounds. The utility of knowing
  this minimal budget relies in that it can aid in the search of optimal or near-optimal
  policies by shrinking down the region of the state space the agent must navigate.
  Simulations illustrate the different nature of probability one constraints against
  the typically used constraints in expectation.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: castellano22a
month: 0
tex_title: Reinforcement Learning with Almost Sure Constraints
firstpage: 559
lastpage: 570
page: 559-570
order: 559
cycles: false
bibtex_author: Castellano, Agustin and Min, Hancheng and Mallada, Enrique and Bazerque,
  Juan Andr\'es
author:
- given: Agustin
  family: Castellano
- given: Hancheng
  family: Min
- given: Enrique
  family: Mallada
- given: Juan Andr√©s
  family: Bazerque
date: 2022-05-11
address:
container-title: Proceedings of The 4th Annual Learning for Dynamics and Control Conference
volume: '168'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 11
pdf: https://proceedings.mlr.press/v168/castellano22a/castellano22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
